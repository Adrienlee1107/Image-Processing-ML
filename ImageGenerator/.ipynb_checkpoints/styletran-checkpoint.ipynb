{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dropout, Concatenate, BatchNormalization, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "import datetime\n",
    "import os\n",
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class styletran():\n",
    "    def __init__(self):\n",
    "        self.cols=256   ## image shape \n",
    "        self.rows=256\n",
    "        self.nchannels=3\n",
    "        self.image_shape=(self.rows, self.cols, self.nchannels)\n",
    "        self.dataset='facades'  ## dataset name\n",
    "        self.data_loader=DataLoader(dataset_name=self.dataset,img_res=(self.rows,self.cols))\n",
    "        \n",
    "        d_outshape=int(self.rows/2**4)\n",
    "        self.dis_patch = (d_outshape, d_outshape, 1)\n",
    "        ## start a generator\n",
    "        self.generator = self.cons_G()\n",
    "        imag1 = Input(shape=self.image_shape)\n",
    "        imag2 = Input(shape=self.image_shape)\n",
    "        test =self.generator(imag2)\n",
    "        ## start a discriminator\n",
    "        self.discriminator=self.cons_D()\n",
    "        self.optimizer=Adam(0.0002,0.5)\n",
    "        self.discriminator.compile(loss='mse',optimizer=self.optimizer,metrics=['accuracy'])\n",
    "        self.discriminator.trainable = False  ## the combined model will not be put into D\n",
    "        \n",
    "        val=self.discriminator([test, imag2])  ## the validity of the fake image\n",
    "        self.combined = Model(inputs=[imag1, imag2], outputs=[val, test])\n",
    "        self.combined.compile(loss=['mse', 'mae'],loss_weights=[1, 100],optimizer=self.optimizer)\n",
    "    def cons_G(self):\n",
    "        def conv2d(layer_input, filters, ker_size=4, bn=True):\n",
    "            ##down-sampling layers\n",
    "            G1 = Conv2D(filters, kernel_size=ker_size, strides=2, padding='same')(layer_input)\n",
    "            G1 = LeakyReLU(alpha=0.2)(G1)\n",
    "            if bn:\n",
    "                lay = BatchNormalization(momentum=0.8)(G1)\n",
    "            return G1\n",
    "        def deconv2d(layer_input, skip_input, filters, ker_size=4, dropout_rate=0):\n",
    "            ##up-sampling layers\n",
    "            G2 = UpSampling2D(size=2)(layer_input)\n",
    "            G2 = Conv2D(filters, kernel_size=ker_size, strides=1, padding='same', activation='relu')(G2)\n",
    "            \n",
    "            if dropout_rate:\n",
    "                G2 = Dropout(dropout_rate)(G2)\n",
    "            G2 = BatchNormalization(momentum=0.8)(G2)\n",
    "            G2 = Concatenate()([G2, skip_input])\n",
    "            return G2\n",
    "        ngf=64  ## n filters in the first layer of the generator\n",
    "        L0=Input(shape=self.image_shape)\n",
    "    ## down-sampling layers\n",
    "        L1 = conv2d(L0, ngf, bn=False)\n",
    "        L2 = conv2d(L1, ngf*2)\n",
    "        L3 = conv2d(L2, ngf*4)\n",
    "        L4 = conv2d(L3, ngf*8)\n",
    "        L5 = conv2d(L4, ngf*8) \n",
    "        L6 = conv2d(L5, ngf*8)\n",
    "        L7 = conv2d(L6, ngf*8)\n",
    "        L8 = conv2d(L7,ngf*8)\n",
    "        ##up-sampling\n",
    "        l1=deconv2d(L8,L7,ngf*8)\n",
    "        l2=deconv2d(l1,L6,ngf*8)\n",
    "        l3=deconv2d(l2,L5,ngf*8)\n",
    "        l4=deconv2d(l3,L4,ngf*8)\n",
    "        l5=deconv2d(l4,L3,ngf*4)\n",
    "        l6=deconv2d(l5,L2,ngf*2)\n",
    "        l7=deconv2d(l6,L1,ngf)\n",
    "        l8 = UpSampling2D(size=2)(l7)\n",
    "        output= Conv2D(self.nchannels, kernel_size=4, strides=1, padding='same', activation='tanh')(l8)\n",
    "    \n",
    "        return Model(L0,output)\n",
    "    def cons_D(self):\n",
    "        def dislayer(layer_input, filters, ker_size=4, bn=True):\n",
    "            ##Discriminator layer\n",
    "            D = Conv2D(filters, kernel_size=ker_size, strides=2, padding='same')(layer_input)\n",
    "            D = LeakyReLU(alpha=0.2)(D)\n",
    "            if bn:\n",
    "                D = BatchNormalization(momentum=0.8)(D)\n",
    "            return D\n",
    "        imag1=Input(shape=self.image_shape)\n",
    "        imag2=Input(shape=self.image_shape)\n",
    "        combined = Concatenate(axis=-1)([imag1, imag2])\n",
    "        ndf=64 ## n filters of the first layer\n",
    "        L1=dislayer(combined, ndf, bn=False)\n",
    "        L2=dislayer(L1,ndf*2)\n",
    "        L3=dislayer(L2,ndf*4)\n",
    "        L4=dislayer(L3,ndf*8)\n",
    "        val=Conv2D(1, kernel_size=4, strides=1, padding='same')(L4)  ## validity of the fake and real picture\n",
    "        return Model([imag1, imag2], val)\n",
    "    \n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "        start_time = datetime.datetime.now()## calculate the iteration time \n",
    "        val = np.ones((batch_size,) + self.dis_patch)\n",
    "        fake = np.zeros((batch_size,) + self.dis_patch)\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imag1, imag2) in enumerate(self.data_loader.load_batch(batch_size)):\n",
    "                ## first train the discriminator\n",
    "                test = self.generator.predict(imag2)\n",
    "            \n",
    "                dis_loss_r=self.discriminator.train_on_batch([imag1, imag2], val)\n",
    "                dis_loss_f=self.discriminator.train_on_batch([test, imag2], fake)\n",
    "                dis_loss=0.5 * np.add(dis_loss_r, dis_loss_f)\n",
    "                ##train the generator\n",
    "                gen_loss = self.combined.train_on_batch([imag1, imag2], [val, imag1])\n",
    "                time = datetime.datetime.now() - start_time\n",
    "                print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % (epoch, \n",
    "                                                                                                       epochs,\n",
    "                                                                                                       batch_i, \n",
    "                                                                                                       self.data_loader.n_batches,\n",
    "                                                                                                       dis_loss[0], \n",
    "                                                                                                       100*dis_loss[1],\n",
    "                                                                                                       gen_loss[0],\n",
    "                                                                                                       time))\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    os.makedirs('images/%s' % self.dataset, exist_ok=True)\n",
    "                    imag1,imag2=self.data_loader.load_data(batch_size=3, is_testing=True)\n",
    "                    fake_image=self.generator.predict(imag2)\n",
    "                    ge_imag = np.concatenate([imag2, fake_image, imag1])\n",
    "                    ge_imag = 0.5 * ge_imag + 0.5\n",
    "                    titles = ['Condition', 'Generated Image', 'Original Image']\n",
    "                    fig, axs = plt.subplots(3,3)\n",
    "                    k=0\n",
    "                    for i in range(3):\n",
    "                        for j in range(3):\n",
    "                            axs[i,j].imshow(ge_imag[k])\n",
    "                            axs[i, j].set_title(titles[i])\n",
    "                            axs[i,j].axis('off')\n",
    "                            k=k+1\n",
    "                    fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset, epoch, batch_i))\n",
    "                    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
